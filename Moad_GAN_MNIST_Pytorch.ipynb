{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understanding GAN models basic concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Image generator\n",
    "    \n",
    "    Takes a noise vector as input and syntheses a single channel image accordingly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of input noise vector\n",
    "            output_dims {int} -- Dimension of the output vector (flatten image)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.Linear(input_dims, 128), \n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        # output hidden layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128, output_dims), \n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of noise vectors in shape (<batch_size>x<input_dims>)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- a batch of flatten image in shape (<batch_size>x<output_dims>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Image discriminator\n",
    "    \n",
    "    Takes a image as input and predict if it is real from the dataset or fake synthesised by the generator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims=1):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the discriminator network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of the flatten input images\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            output_dims {int} -- Predicted probability (default: {1})\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "  \n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.Linear(input_dims, 784),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(784, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of 2D image in shape (<batch_size>xHxW)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- predicted probabilities (<batch_size>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def show_result(G_net, z_, num_epoch, show=False, save=False, path='result.png'):\n",
    "    \"\"\"Result visualisation\n",
    "    \n",
    "    Show and save the generated figures in the grid fashion\n",
    "    \n",
    "    Arguments:\n",
    "        G_net {[nn.Module]} -- The generator instant\n",
    "        z_ {[Tensor]} -- Input noise vectors\n",
    "        num_epoch {[int]} -- Indicate how many epoch has the generator been trained\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the images (default: {False})\n",
    "        save {bool} -- If to store the images (default: {False})\n",
    "        path {str} -- path to store the images (default: {'result.png'})\n",
    "    \"\"\"\n",
    "\n",
    "    ###  TODO: complete the rest of part\n",
    "    # hint: use plt.subplots to construct grid\n",
    "    # hint: use plt.imshow and plt.savefig to display and store the images\n",
    "    \n",
    "    show_data_fake = G_net(z_)\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    \n",
    "    for ax, img in zip(axes.flatten(), show_data_fake):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "            \n",
    "    fig.savefig(path)\n",
    "    \n",
    "    \n",
    "\n",
    "def show_train_hist(hist, show=False, save=False, path='Train_hist.png'):\n",
    "    \"\"\"Loss tracker\n",
    "    \n",
    "    Plot the losses of generator and discriminator independently to see the trend\n",
    "    \n",
    "    Arguments:\n",
    "        hist {[dict]} -- Tracking variables\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the figure (default: {False})\n",
    "        save {bool} -- If to store the figure (default: {False})\n",
    "        path {str} -- path to store the figure (default: {'Train_hist.png'})\n",
    "    \"\"\"\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "\n",
    "def create_noise(num, dim):\n",
    "    \"\"\"Noise constructor\n",
    "    \n",
    "    returns a tensor filled with random numbers from a standard normal distribution\n",
    "    \n",
    "    Arguments:\n",
    "        num {int} -- Number of vectors\n",
    "        dim {int} -- Dimension of vectors\n",
    "    \n",
    "    Returns:\n",
    "        [Tensor] -- the generated noise vector batch\n",
    "    \"\"\"\n",
    "    return torch.randn(num, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_dir = './MNIST_data/'\n",
    "    save_dir = './MNIST_GAN_results/'\n",
    "    image_save_dir = './MNIST_GAN_results/results'\n",
    "\n",
    "    # create folder if not exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    if not os.path.exists(image_save_dir):\n",
    "        os.mkdir(image_save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes here to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # training parameters : change here\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0002\n",
    "    epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # parameters for Models\n",
    "    image_size = 28\n",
    "    G_input_dim = 100\n",
    "    G_output_dim = image_size * image_size\n",
    "    D_input_dim = image_size * image_size\n",
    "    D_output_dim = 1\n",
    "    hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)\n",
    "\n",
    "    # Binary Cross Entropy Loss function\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    # Initialise the Optimizers\n",
    "    G_optimizer = torch.optim.Adam(G_net.parameters(), lr=learning_rate)\n",
    "    D_optimizer = torch.optim.Adam(D_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # tracking variables\n",
    "    train_hist = {}\n",
    "    train_hist['D_losses'] = []\n",
    "    train_hist['G_losses'] = []\n",
    "    train_hist['per_epoch_ptimes'] = []\n",
    "    train_hist['total_ptime'] = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        G_net.train()\n",
    "        D_net.train()\n",
    "        Loss_G = []\n",
    "        Loss_D = []\n",
    "        epoch_start_time = time.time()\n",
    "        for (image, _) in tqdm(train_loader):\n",
    "            image = image.to(device)\n",
    "            b_size = len(image)\n",
    "            # creat real and fake labels\n",
    "            real_label = torch.ones(b_size, 1).to(device)\n",
    "            fake_label = torch.zeros(b_size, 1).to(device)\n",
    "\n",
    "            # generate fake images \n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "            data_real = image.view(b_size, D_input_dim)\n",
    "\n",
    "            # --------train the discriminator network----------\n",
    "            # compute the loss for real and fake images\n",
    "            output_real = D_net(data_real)\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_real = criterion(output_real, real_label)\n",
    "            loss_fake = criterion(output_fake, fake_label)\n",
    "            loss_d = loss_real + loss_fake\n",
    "\n",
    "            # back propagation\n",
    "            D_optimizer.zero_grad()\n",
    "            loss_d.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            # -------- train the generator network-----------\n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "\n",
    "            # compute the loss for generator network\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_g = criterion(output_fake, real_label)\n",
    "\n",
    "            ## back propagation\n",
    "            G_optimizer.zero_grad()\n",
    "            loss_g.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            ## store the loss of each iter\n",
    "            Loss_D.append(loss_d.item())\n",
    "            Loss_G.append(loss_g.item())\n",
    "\n",
    "        epoch_loss_g = np.mean(Loss_G)  # mean generator loss for the epoch\n",
    "        epoch_loss_d = np.mean(Loss_D)  # mean discriminator loss for the epoch\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n",
    "        print(\"Generator loss: %.8f, Discriminator loss: %.8f\" % (epoch_loss_g, epoch_loss_d))\n",
    "\n",
    "        path = image_save_dir + '/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "        show_result(G_net, create_noise(25, 100).to(device), (epoch + 1), save=True, path=path)\n",
    "        \n",
    "        # record the loss for every epoch\n",
    "        train_hist['G_losses'].append(epoch_loss_g)\n",
    "        train_hist['D_losses'].append(epoch_loss_d)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n",
    "        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n",
    "    print(\"Training finish!... save training results\")\n",
    "    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n",
    "        pickle.dump(train_hist, f)\n",
    "    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generative Adversarial Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. modify architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Image generator\n",
    "    \n",
    "    Takes a noise vector as input and syntheses a single channel image accordingly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of input noise vector\n",
    "            output_dims {int} -- Dimension of the output vector (flatten image)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "\n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 100), \n",
    "#            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(100, 256), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 512), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 1024), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )  \n",
    "        \n",
    "        # output hidden layer\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(1024, output_dims), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of noise vectors in shape (<batch_size>x<input_dims>)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- a batch of flatten image in shape (<batch_size>x<output_dims>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Image discriminator\n",
    "    \n",
    "    Takes a image as input and predict if it is real from the dataset or fake synthesised by the generator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims=1):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the discriminator network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of the flatten input images\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            output_dims {int} -- Predicted probability (default: {1})\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "        \n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 784),\n",
    "#            nn.LeakyReLU(0.2),\n",
    "#            nn.Dropout(0.3)\n",
    "#        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of 2D image in shape (<batch_size>xHxW)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- predicted probabilities (<batch_size>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_result(G_net, z_, num_epoch, show=False, save=False, path='result.png'):\n",
    "    \"\"\"Result visualisation\n",
    "    \n",
    "    Show and save the generated figures in the grid fashion\n",
    "    \n",
    "    Arguments:\n",
    "        G_net {[nn.Module]} -- The generator instant\n",
    "        z_ {[Tensor]} -- Input noise vectors\n",
    "        num_epoch {[int]} -- Indicate how many epoch has the generator been trained\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the images (default: {False})\n",
    "        save {bool} -- If to store the images (default: {False})\n",
    "        path {str} -- path to store the images (default: {'result.png'})\n",
    "    \"\"\"\n",
    "\n",
    "    ###  TODO: complete the rest of part\n",
    "    # hint: use plt.subplots to construct grid\n",
    "    # hint: use plt.imshow and plt.savefig to display and store the images\n",
    "    \n",
    "    show_data_fake = G_net(z_)\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    \n",
    "    for ax, img in zip(axes.flatten(), show_data_fake):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        \n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()   \n",
    "\n",
    "    \n",
    "\n",
    "def show_train_hist(hist, show=False, save=False, path='Train_hist.png'):\n",
    "    \"\"\"Loss tracker\n",
    "    \n",
    "    Plot the losses of generator and discriminator independently to see the trend\n",
    "    \n",
    "    Arguments:\n",
    "        hist {[dict]} -- Tracking variables\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the figure (default: {False})\n",
    "        save {bool} -- If to store the figure (default: {False})\n",
    "        path {str} -- path to store the figure (default: {'Train_hist.png'})\n",
    "    \"\"\"\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_noise(num, dim):\n",
    "    \"\"\"Noise constructor\n",
    "    \n",
    "    returns a tensor filled with random numbers from a standard normal distribution\n",
    "    \n",
    "    Arguments:\n",
    "        num {int} -- Number of vectors\n",
    "        dim {int} -- Dimension of vectors\n",
    "    \n",
    "    Returns:\n",
    "        [Tensor] -- the generated noise vector batch\n",
    "    \"\"\"\n",
    "    return torch.randn(num, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_dir = './MNIST_data/'\n",
    "    save_dir = './MNIST_GAN_results/'\n",
    "    image_save_dir = './MNIST_GAN_results/results'\n",
    "\n",
    "    # create folder if not exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    if not os.path.exists(image_save_dir):\n",
    "        os.mkdir(image_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # training parameters\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0002\n",
    "    epochs = 100\n",
    "\n",
    "    # parameters for Models\n",
    "    image_size = 28\n",
    "    G_input_dim = 100\n",
    "    G_output_dim = image_size * image_size\n",
    "    D_input_dim = image_size * image_size\n",
    "    D_output_dim = 1\n",
    "    hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)\n",
    "\n",
    "    # Binary Cross Entropy Loss function\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    # Initialise the Optimizers\n",
    "    G_optimizer = torch.optim.Adam(G_net.parameters(), lr=learning_rate)\n",
    "    D_optimizer = torch.optim.Adam(D_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # tracking variables\n",
    "    train_hist = {}\n",
    "    train_hist['D_losses'] = []\n",
    "    train_hist['G_losses'] = []\n",
    "    train_hist['per_epoch_ptimes'] = []\n",
    "    train_hist['total_ptime'] = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        G_net.train()\n",
    "        D_net.train()\n",
    "        Loss_G = []\n",
    "        Loss_D = []\n",
    "        epoch_start_time = time.time()\n",
    "        for (image, _) in tqdm(train_loader):\n",
    "            image = image.to(device)\n",
    "            b_size = len(image)\n",
    "            # creat real and fake labels\n",
    "            real_label = torch.ones(b_size, 1).to(device)\n",
    "            fake_label = torch.zeros(b_size, 1).to(device)\n",
    "\n",
    "            # generate fake images \n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "            data_real = image.view(b_size, D_input_dim)\n",
    "\n",
    "            # --------train the discriminator network----------\n",
    "            # compute the loss for real and fake images\n",
    "            output_real = D_net(data_real)\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_real = criterion(output_real, real_label)\n",
    "            loss_fake = criterion(output_fake, fake_label)\n",
    "            loss_d = loss_real + loss_fake\n",
    "\n",
    "            # back propagation\n",
    "            D_optimizer.zero_grad()\n",
    "            loss_d.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            # -------- train the generator network-----------\n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "\n",
    "            # compute the loss for generator network\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_g = criterion(output_fake, real_label)\n",
    "\n",
    "            ## back propagation\n",
    "            G_optimizer.zero_grad()\n",
    "            loss_g.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            ## store the loss of each iter\n",
    "            Loss_D.append(loss_d.item())\n",
    "            Loss_G.append(loss_g.item())\n",
    "\n",
    "        epoch_loss_g = np.mean(Loss_G)  # mean generator loss for the epoch\n",
    "        epoch_loss_d = np.mean(Loss_D)  # mean discriminator loss for the epoch\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n",
    "        print(\"Generator loss: %.8f, Discriminator loss: %.8f\" % (epoch_loss_g, epoch_loss_d))\n",
    "\n",
    "        path = image_save_dir + '/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "        show_result(G_net, create_noise(25, 100).to(device), (epoch + 1), save=True, path=path)\n",
    "        \n",
    "        \n",
    "        if epoch == 9 or epoch == 19 or epoch == 49 or epoch == 99:\n",
    "            print()\n",
    "            path1 = generated_images + '/MNIST_GAN_Generated_epoch_images_' + str(epoch+1) + '.png'\n",
    "            show_generated_images(data_fake , (epoch + 1), save=True, path=path1)\n",
    "        \n",
    "\n",
    "        # record the loss for every epoch\n",
    "        train_hist['G_losses'].append(epoch_loss_g)\n",
    "        train_hist['D_losses'].append(epoch_loss_d)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n",
    "        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n",
    "    print(\"Training finish!... save training results\")\n",
    "    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n",
    "        pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dropout removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Image generator\n",
    "    \n",
    "    Takes a noise vector as input and syntheses a single channel image accordingly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of input noise vector\n",
    "            output_dims {int} -- Dimension of the output vector (flatten image)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "\n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 100), \n",
    "#            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(100, 256), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 512), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 1024), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )  \n",
    "        \n",
    "        # output hidden layer\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(1024, output_dims), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of noise vectors in shape (<batch_size>x<input_dims>)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- a batch of flatten image in shape (<batch_size>x<output_dims>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Image discriminator\n",
    "    \n",
    "    Takes a image as input and predict if it is real from the dataset or fake synthesised by the generator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims=1):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the discriminator network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of the flatten input images\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            output_dims {int} -- Predicted probability (default: {1})\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "        \n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 784),\n",
    "#            nn.LeakyReLU(0.2),\n",
    "#            nn.Dropout(0.3)\n",
    "#        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of 2D image in shape (<batch_size>xHxW)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- predicted probabilities (<batch_size>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_result(G_net, z_, num_epoch, show=False, save=False, path='result.png'):\n",
    "    \"\"\"Result visualisation\n",
    "    \n",
    "    Show and save the generated figures in the grid fashion\n",
    "    \n",
    "    Arguments:\n",
    "        G_net {[nn.Module]} -- The generator instant\n",
    "        z_ {[Tensor]} -- Input noise vectors\n",
    "        num_epoch {[int]} -- Indicate how many epoch has the generator been trained\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the images (default: {False})\n",
    "        save {bool} -- If to store the images (default: {False})\n",
    "        path {str} -- path to store the images (default: {'result.png'})\n",
    "    \"\"\"\n",
    "\n",
    "    ###  TODO: complete the rest of part\n",
    "    # hint: use plt.subplots to construct grid\n",
    "    # hint: use plt.imshow and plt.savefig to display and store the images\n",
    "    \n",
    "    show_data_fake = G_net(z_)\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    \n",
    "    for ax, img in zip(axes.flatten(), show_data_fake):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        \n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def show_train_hist(hist, show=False, save=False, path='Train_hist.png'):\n",
    "    \"\"\"Loss tracker\n",
    "    \n",
    "    Plot the losses of generator and discriminator independently to see the trend\n",
    "    \n",
    "    Arguments:\n",
    "        hist {[dict]} -- Tracking variables\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the figure (default: {False})\n",
    "        save {bool} -- If to store the figure (default: {False})\n",
    "        path {str} -- path to store the figure (default: {'Train_hist.png'})\n",
    "    \"\"\"\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_noise(num, dim):\n",
    "    \"\"\"Noise constructor\n",
    "    \n",
    "    returns a tensor filled with random numbers from a standard normal distribution\n",
    "    \n",
    "    Arguments:\n",
    "        num {int} -- Number of vectors\n",
    "        dim {int} -- Dimension of vectors\n",
    "    \n",
    "    Returns:\n",
    "        [Tensor] -- the generated noise vector batch\n",
    "    \"\"\"\n",
    "    return torch.randn(num, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_dir = './MNIST_data/'\n",
    "    save_dir = './MNIST_GAN_results/'\n",
    "    image_save_dir = './MNIST_GAN_results/results'\n",
    "    generated_images = './MNIST_GAN_results/generated images'\n",
    "\n",
    "    # create folder if not exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    if not os.path.exists(image_save_dir):\n",
    "        os.mkdir(image_save_dir)\n",
    "    if not os.path.exists(generated_images):\n",
    "        os.mkdir(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # training parameters\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0002\n",
    "    epochs = 100\n",
    "\n",
    "    # parameters for Models\n",
    "    image_size = 28\n",
    "    G_input_dim = 100\n",
    "    G_output_dim = image_size * image_size\n",
    "    D_input_dim = image_size * image_size\n",
    "    D_output_dim = 1\n",
    "    hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)\n",
    "\n",
    "    # Binary Cross Entropy Loss function\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    # Initialise the Optimizers\n",
    "    G_optimizer = torch.optim.Adam(G_net.parameters(), lr=learning_rate)\n",
    "    D_optimizer = torch.optim.Adam(D_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # tracking variables\n",
    "    train_hist = {}\n",
    "    train_hist['D_losses'] = []\n",
    "    train_hist['G_losses'] = []\n",
    "    train_hist['per_epoch_ptimes'] = []\n",
    "    train_hist['total_ptime'] = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        G_net.train()\n",
    "        D_net.train()\n",
    "        Loss_G = []\n",
    "        Loss_D = []\n",
    "        epoch_start_time = time.time()\n",
    "        for (image, _) in tqdm(train_loader):\n",
    "            image = image.to(device)\n",
    "            b_size = len(image)\n",
    "            # creat real and fake labels\n",
    "            real_label = torch.ones(b_size, 1).to(device)\n",
    "            fake_label = torch.zeros(b_size, 1).to(device)\n",
    "\n",
    "            # generate fake images \n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "            data_real = image.view(b_size, D_input_dim)\n",
    "\n",
    "            # --------train the discriminator network----------\n",
    "            # compute the loss for real and fake images\n",
    "            output_real = D_net(data_real)\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_real = criterion(output_real, real_label)\n",
    "            loss_fake = criterion(output_fake, fake_label)\n",
    "            loss_d = loss_real + loss_fake\n",
    "\n",
    "            # back propagation\n",
    "            D_optimizer.zero_grad()\n",
    "            loss_d.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            # -------- train the generator network-----------\n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "\n",
    "            # compute the loss for generator network\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_g = criterion(output_fake, real_label)\n",
    "\n",
    "            ## back propagation\n",
    "            G_optimizer.zero_grad()\n",
    "            loss_g.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            ## store the loss of each iter\n",
    "            Loss_D.append(loss_d.item())\n",
    "            Loss_G.append(loss_g.item())\n",
    "\n",
    "        epoch_loss_g = np.mean(Loss_G)  # mean generator loss for the epoch\n",
    "        epoch_loss_d = np.mean(Loss_D)  # mean discriminator loss for the epoch\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n",
    "        print(\"Generator loss: %.8f, Discriminator loss: %.8f\" % (epoch_loss_g, epoch_loss_d))\n",
    "\n",
    "        path = image_save_dir + '/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "        show_result(G_net, create_noise(25, 100).to(device), (epoch + 1), save=True, path=path)\n",
    "        \n",
    "        \n",
    "        if epoch == 9 or epoch == 19 or epoch == 49 or epoch == 99:\n",
    "            print()\n",
    "            path1 = generated_images + '/MNIST_GAN_Generated_epoch_images_' + str(epoch+1) + '.png'\n",
    "            show_generated_images(data_fake , (epoch + 1), save=True, path=path1)\n",
    "        \n",
    "\n",
    "        # record the loss for every epoch\n",
    "        train_hist['G_losses'].append(epoch_loss_g)\n",
    "        train_hist['D_losses'].append(epoch_loss_d)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n",
    "        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n",
    "    print(\"Training finish!... save training results\")\n",
    "    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n",
    "        pickle.dump(train_hist, f)\n",
    "    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n",
    "        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n",
    "    print(\"Training finish!... save training results\")\n",
    "    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n",
    "        pickle.dump(train_hist, f)\n",
    "    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. save generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Image generator\n",
    "    \n",
    "    Takes a noise vector as input and syntheses a single channel image accordingly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of input noise vector\n",
    "            output_dims {int} -- Dimension of the output vector (flatten image)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "\n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 100), \n",
    "#            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(100, 256), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 512), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 1024), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )  \n",
    "        \n",
    "        # output hidden layer\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(1024, output_dims), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of noise vectors in shape (<batch_size>x<input_dims>)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- a batch of flatten image in shape (<batch_size>x<output_dims>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Image discriminator\n",
    "    \n",
    "    Takes a image as input and predict if it is real from the dataset or fake synthesised by the generator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims=1):\n",
    "        \"\"\"Init function\n",
    "        \n",
    "        Declare the discriminator network structure as indicated in CW2 Guidance\n",
    "        \n",
    "        Arguments:\n",
    "            input_dims {int} -- Dimension of the flatten input images\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            output_dims {int} -- Predicted probability (default: {1})\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ###  TODO: Change the architecture and value as CW2 Guidance required\n",
    "        \n",
    "#        self.fc0 = nn.Sequential(\n",
    "#            nn.Linear(input_dims, 784),\n",
    "#            nn.LeakyReLU(0.2),\n",
    "#            nn.Dropout(0.3)\n",
    "#        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function\n",
    "        \n",
    "        Arguments:\n",
    "            x {Tensor} -- a batch of 2D image in shape (<batch_size>xHxW)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor -- predicted probabilities (<batch_size>)\n",
    "        \"\"\"\n",
    "        ###  TODO: modify to be consistent with the network structure\n",
    "\n",
    "#        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_result(G_net, z_, num_epoch, show=False, save=False, path='result.png'):\n",
    "    \"\"\"Result visualisation\n",
    "    \n",
    "    Show and save the generated figures in the grid fashion\n",
    "    \n",
    "    Arguments:\n",
    "        G_net {[nn.Module]} -- The generator instant\n",
    "        z_ {[Tensor]} -- Input noise vectors\n",
    "        num_epoch {[int]} -- Indicate how many epoch has the generator been trained\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the images (default: {False})\n",
    "        save {bool} -- If to store the images (default: {False})\n",
    "        path {str} -- path to store the images (default: {'result.png'})\n",
    "    \"\"\"\n",
    "\n",
    "    ###  TODO: complete the rest of part\n",
    "    # hint: use plt.subplots to construct grid\n",
    "    # hint: use plt.imshow and plt.savefig to display and store the images\n",
    "    \n",
    "    show_data_fake = G_net(z_)\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    \n",
    "    for ax, img in zip(axes.flatten(), show_data_fake):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        \n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()   \n",
    "\n",
    "\n",
    "def show_train_hist(hist, show=False, save=False, path='Train_hist.png'):\n",
    "    \"\"\"Loss tracker\n",
    "    \n",
    "    Plot the losses of generator and discriminator independently to see the trend\n",
    "    \n",
    "    Arguments:\n",
    "        hist {[dict]} -- Tracking variables\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        show {bool} -- If to display the figure (default: {False})\n",
    "        save {bool} -- If to store the figure (default: {False})\n",
    "        path {str} -- path to store the figure (default: {'Train_hist.png'})\n",
    "    \"\"\"\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_noise(num, dim):\n",
    "    \"\"\"Noise constructor\n",
    "    \n",
    "    returns a tensor filled with random numbers from a standard normal distribution\n",
    "    \n",
    "    Arguments:\n",
    "        num {int} -- Number of vectors\n",
    "        dim {int} -- Dimension of vectors\n",
    "    \n",
    "    Returns:\n",
    "        [Tensor] -- the generated noise vector batch\n",
    "    \"\"\"\n",
    "    return torch.randn(num, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_dir = './MNIST_data/'\n",
    "    save_dir = './MNIST_GAN_results/'\n",
    "    image_save_dir = './MNIST_GAN_results/results'\n",
    "    generated_images = './MNIST_GAN_results/generated images'\n",
    "\n",
    "    # create folder if not exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    if not os.path.exists(image_save_dir):\n",
    "        os.mkdir(image_save_dir)\n",
    "    if not os.path.exists(generated_images):\n",
    "        os.mkdir(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # training parameters\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0002\n",
    "    epochs = 100\n",
    "\n",
    "    # parameters for Models\n",
    "    image_size = 28\n",
    "    G_input_dim = 100\n",
    "    G_output_dim = image_size * image_size\n",
    "    D_input_dim = image_size * image_size\n",
    "    D_output_dim = 1\n",
    "    hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # declare the generator and discriminator networks    \n",
    "    G_net = Generator(G_input_dim, G_output_dim).to(device)\n",
    "    D_net = Discriminator(D_input_dim, D_output_dim).to(device)\n",
    "\n",
    "    # Binary Cross Entropy Loss function\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    # Initialise the Optimizers\n",
    "    G_optimizer = torch.optim.Adam(G_net.parameters(), lr=learning_rate)\n",
    "    D_optimizer = torch.optim.Adam(D_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # tracking variables\n",
    "    train_hist = {}\n",
    "    train_hist['D_losses'] = []\n",
    "    train_hist['G_losses'] = []\n",
    "    train_hist['per_epoch_ptimes'] = []\n",
    "    train_hist['total_ptime'] = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        G_net.train()\n",
    "        D_net.train()\n",
    "        Loss_G = []\n",
    "        Loss_D = []\n",
    "        epoch_start_time = time.time()\n",
    "        for (image, _) in tqdm(train_loader):\n",
    "            image = image.to(device)\n",
    "            b_size = len(image)\n",
    "            # creat real and fake labels\n",
    "            real_label = torch.ones(b_size, 1).to(device)\n",
    "            fake_label = torch.zeros(b_size, 1).to(device)\n",
    "\n",
    "            # generate fake images \n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "            data_real = image.view(b_size, D_input_dim)\n",
    "\n",
    "            # --------train the discriminator network----------\n",
    "            # compute the loss for real and fake images\n",
    "            output_real = D_net(data_real)\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_real = criterion(output_real, real_label)\n",
    "            loss_fake = criterion(output_fake, fake_label)\n",
    "            loss_d = loss_real + loss_fake\n",
    "\n",
    "            # back propagation\n",
    "            D_optimizer.zero_grad()\n",
    "            loss_d.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            # -------- train the generator network-----------\n",
    "            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n",
    "\n",
    "            # compute the loss for generator network\n",
    "            output_fake = D_net(data_fake)\n",
    "            loss_g = criterion(output_fake, real_label)\n",
    "\n",
    "            ## back propagation\n",
    "            G_optimizer.zero_grad()\n",
    "            loss_g.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            ## store the loss of each iter\n",
    "            Loss_D.append(loss_d.item())\n",
    "            Loss_G.append(loss_g.item())\n",
    "\n",
    "        epoch_loss_g = np.mean(Loss_G)  # mean generator loss for the epoch\n",
    "        epoch_loss_d = np.mean(Loss_D)  # mean discriminator loss for the epoch\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n",
    "        print(\"Generator loss: %.8f, Discriminator loss: %.8f\" % (epoch_loss_g, epoch_loss_d))\n",
    "\n",
    "        if epoch == 9 or epoch == 19 or epoch == 49 or epoch == 99:\n",
    "            path = image_save_dir + '/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "            show_result(G_net, create_noise(25, 100).to(device), (epoch + 1), save=True, path=path)\n",
    "        \n",
    "        \n",
    "        #if epoch == 9 or epoch == 19 or epoch == 49 or epoch == 99:\n",
    "            #print()\n",
    "            #path1 = generated_images + '/MNIST_GAN_Generated_epoch_images_' + str(epoch+1) + '.png'\n",
    "            #show_generated_images(data_fake , (epoch + 1), save=True, path=path1)\n",
    "        \n",
    "\n",
    "        # record the loss for every epoch\n",
    "        train_hist['G_losses'].append(epoch_loss_g)\n",
    "        train_hist['D_losses'].append(epoch_loss_d)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n",
    "        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n",
    "    print(\"Training finish!... save training results\")\n",
    "    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n",
    "        pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
